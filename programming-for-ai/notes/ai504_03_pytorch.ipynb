{"cells":[{"cell_type":"markdown","metadata":{"id":"QbjN-8O3sp9I"},"source":["# Week 3: PyTorch, Logistic Regression and MLP"]},{"cell_type":"markdown","metadata":{"id":"Xd7_qFa6sp9I"},"source":["- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n","- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n","- We will use simple linear model and multi-layer perceptron (MLP) in this class\n","\n","If you have any questions, feel free to ask\n","- For additional questions, post questions in classum."]},{"cell_type":"markdown","metadata":{"id":"0_6tgh_lsp9I"},"source":["## Why PyTorch?"]},{"cell_type":"markdown","metadata":{"id":"EMwIjuVvsp9J"},"source":["- Intuitive and concise code\n","- Define by Run method (Tensorflow is Define and Run method)\n","- High compatibility with Numpy (almost one-to-one mapping)"]},{"cell_type":"markdown","metadata":{"id":"6O3b-lLfsp9J"},"source":["![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"]},{"cell_type":"markdown","metadata":{"id":"AofEmIygsp9J"},"source":["## 0. Prelim: Load packages & GPU setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fia9Dz_Osp9J","outputId":"f3087112-2916-4d3e-9d8c-07e9a5059d34","executionInfo":{"status":"ok","timestamp":1726626512301,"user_tz":-540,"elapsed":1061,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep 18 02:28:31 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["# visualize current GPU usages in your server\n","!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"pTj8gTCqsp9K","executionInfo":{"status":"ok","timestamp":1726626514591,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# set gpu by number\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXLR6ixYsp9L","outputId":"0c7c5614-61df-4487-b58d-e238f3834937","executionInfo":{"status":"ok","timestamp":1726626530388,"user_tz":-540,"elapsed":14743,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"]}],"source":["# load packages\n","!pip install torch\n","!pip install numpy\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yk1UF7XYsp9L","outputId":"4d71955b-132d-4896-a553-5216cade9df1","executionInfo":{"status":"ok","timestamp":1726626530388,"user_tz":-540,"elapsed":6,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.4.0+cu121\n"]}],"source":["# print the version of PyTorch\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"8vUJG0Ofsp9L"},"source":["## 1. PyTorch Tensors and Numpy"]},{"cell_type":"markdown","metadata":{"id":"qG5rTO8tsp9L"},"source":["PyTorch use **tensor**: the basic data structure in PyTorch.\\\n","**Tensor: n-dimensional array + GPU calculation is supported**\\\n","**Almost the same with Numpy array**"]},{"cell_type":"markdown","metadata":{"id":"W0luwTVGsp9L"},"source":["![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"]},{"cell_type":"markdown","metadata":{"id":"DPaY0_2bsp9M"},"source":["### PyTorch Tensors and Numpy shares almost identical grammer"]},{"cell_type":"markdown","metadata":{"id":"91ye-IRxsp9M"},"source":["\n","**We will show some examples of:**\n","- Same operation with identical grammer\n","- Same operation with different grammer\n","- Different operation with same grammer\n","\n","**We will not handle all examples in this class :(**\n","- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"]},{"cell_type":"markdown","metadata":{"id":"N5RrHkDdsp9O"},"source":["**First! Define Numpy array and PyTorch tensor**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dT6LsNonsp9O","outputId":"88f44c80-fad1-42e2-923d-8695c8f5701f","executionInfo":{"status":"ok","timestamp":1726626530388,"user_tz":-540,"elapsed":5,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 2 3 4]\n","[5 6 7 8]\n","tensor([1, 2, 3, 4])\n","tensor([5, 6, 7, 8])\n"]}],"source":["np_array_1 = np.array([1, 2, 3, 4])\n","np_array_2 = np.array([5, 6, 7, 8])\n","torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n","torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n","\n","print (np_array_1)\n","print (np_array_2)\n","print (torch_tensor_1)\n","print (torch_tensor_2)"]},{"cell_type":"markdown","metadata":{"id":"tyb-3ySEsp9O"},"source":["**1) Same operations with identical grammer**\n","\n","Example) Get the shape of the tensor"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVKGdRwNsp9P","outputId":"12880549-c681-4a31-abd5-baf5949148ee","executionInfo":{"status":"ok","timestamp":1726626533841,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(4,)\n","torch.Size([4])\n","torch.Size([4])\n"]}],"source":["# numpy\n","print (np_array_1.shape)\n","\n","# torch\n","print (torch_tensor_1.shape)\n","print (torch_tensor_1.size()) # size() and shape operation is identical in torch"]},{"cell_type":"markdown","metadata":{"id":"9Ph6yZ4Nsp9P"},"source":["**2) Same operations with different grammer**\n","\n","Example 1) Concatenate two tensors\n","- numpy use `np.concatenate`\n","- torch use `torch.cat`\n","- IMPORTANT: axis (numpy) and dim (torch) is identical"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6AZYswBsp9P","outputId":"26a4c923-81f1-4338-993a-e8e97fab921b","executionInfo":{"status":"ok","timestamp":1726626536854,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["----numpy----\n","[1 2 3 4 5 6 7 8]\n","----torch----\n","tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"]}],"source":["# numpy\n","np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n","print ('----numpy----')\n","print (np_concate)\n","\n","# torch\n","torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n","print ('----torch----')\n","print (torch_concate)"]},{"cell_type":"markdown","metadata":{"id":"9_baPgLasp9Q"},"source":["Example 2) reshape the tensor shape\n","- numpy use `X.reshape`\n","- torch use `X.view`\n","- IMPORTANT: axis (numpy) and dim (torch) is identical"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBMJhl6tsp9Q","outputId":"5b440213-69af-4f13-8ab1-82704bfd5533","executionInfo":{"status":"ok","timestamp":1726626538314,"user_tz":-540,"elapsed":5,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["----numpy----\n","[[1 2]\n"," [3 4]\n"," [5 6]\n"," [7 8]]\n","(4, 2)\n","----torch----\n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","torch.Size([4, 2])\n"]}],"source":["# numpy\n","np_reshaped = np_concate.reshape(4, 2)\n","print ('----numpy----')\n","print (np_reshaped)\n","print (np_reshaped.shape)\n","\n","# torch\n","torch_reshaped = torch_concate.view(4, 2)\n","print ('----torch----')\n","print (torch_reshaped)\n","print (torch_reshaped.shape)"]},{"cell_type":"markdown","metadata":{"id":"0nQopYNcsp9Q"},"source":["**3) Different operations with same grammer (Confusing operations)**\n","\n","Example) manipulation tensors\n","- Same grammer `repeat`  has different operations"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bL05Z6GYsp9R","outputId":"0bd9db40-9a11-4312-db7b-e08b21d3f857","executionInfo":{"status":"ok","timestamp":1726626538314,"user_tz":-540,"elapsed":4,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["----numpy----\n","[1 2 3]\n","[1 1 2 2 3 3]\n","----torch----\n","tensor([1, 2, 3])\n","tensor([1, 2, 3, 1, 2, 3])\n","----obtain the same result-----\n","tensor([[1],\n","        [2],\n","        [3]])\n","tensor([[1, 1],\n","        [2, 2],\n","        [3, 3]])\n","tensor([1, 1, 2, 2, 3, 3])\n"]}],"source":["x = np.array([1, 2, 3])\n","x_repeat = x.repeat(2)\n","\n","print ('----numpy----')\n","print (x)\n","print (x_repeat)\n","\n","x = torch.tensor([1, 2, 3])\n","x_repeat = x.repeat(2)\n","\n","print ('----torch----')\n","print (x)\n","print (x_repeat)\n","\n","# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n","print('----obtain the same result-----')\n","x_repeat = x.view(3, 1)\n","print (x_repeat)\n","\n","x_repeat = x_repeat.repeat(1, 2)\n","print (x_repeat)\n","\n","x_repeat = x_repeat.view(-1)\n","print (x_repeat)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQP6FnKbsp9R","outputId":"0bb5dc17-123d-43c1-d9f2-d90fb3219f14","executionInfo":{"status":"ok","timestamp":1726626539489,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n","tensor([[1, 2, 3],\n","        [1, 2, 3],\n","        [1, 2, 3],\n","        [1, 2, 3]])\n","tensor([[1, 2, 3],\n","        [1, 2, 3],\n","        [1, 2, 3],\n","        [1, 2, 3]])\n"]}],"source":["# similar manipulation operation: stack & repeat\n","x = torch.tensor([1, 2, 3])\n","x_repeat = x.repeat(4)\n","x_stack = torch.stack([x, x, x, x])\n","\n","print (x_repeat)\n","print (x_stack)\n","print (x_repeat.view(4, 3)) # reshape x"]},{"cell_type":"markdown","metadata":{"id":"S5eWKE4Nsp9R"},"source":["## 2. Tensor operations under GPU utilization"]},{"cell_type":"markdown","metadata":{"id":"pXgOePsysp9R"},"source":["Deep learning frameworks utilize GPUs to accelarate computations.\n","\n","In this section, we will learn **how to utilize GPU** in PyTorch"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEnKzXeIsp9S","outputId":"2e9a4e34-0eaa-4563-c5ab-52ab8ea89d92","executionInfo":{"status":"ok","timestamp":1726626540886,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["print(torch.cuda.is_available())  # Is GPU accessible?"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"v4QF2qY3sp9S","executionInfo":{"status":"ok","timestamp":1726626541399,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["a = torch.ones(3)\n","b = torch.randn(100, 50, 3)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVxUVMzWsp9S","outputId":"36130748-1f7e-4ea2-97a5-f7541eba1567","executionInfo":{"status":"ok","timestamp":1726626541937,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n","cpu\n"]}],"source":["print(a.device)\n","print(b.device)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Sa9qkmausp9S","executionInfo":{"status":"ok","timestamp":1726626542383,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["c = a + b"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQ2pfjr6sp9T","outputId":"eca8232d-52b7-45ba-cc74-919ae0ad314b","executionInfo":{"status":"ok","timestamp":1726626544166,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["print(c.device)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"YBmLLHZ5sp9U","executionInfo":{"status":"ok","timestamp":1726626544716,"user_tz":-540,"elapsed":552,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# upload a and b to GPU\n","a = a.to('cuda')\n","b = b.to('cuda')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynnrZrqTsp9U","outputId":"399a68ae-602d-42a0-8103-66a4b2b3d212","executionInfo":{"status":"ok","timestamp":1726626544716,"user_tz":-540,"elapsed":4,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","cuda:0\n"]}],"source":["print(a.device)\n","print(b.device)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"VhoePABXsp9U","executionInfo":{"status":"ok","timestamp":1726626544717,"user_tz":-540,"elapsed":4,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["c = a + b"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLvhKI2Dsp9U","outputId":"300542a5-d405-4c48-e6b0-0806b0a754c9","executionInfo":{"status":"ok","timestamp":1726626544717,"user_tz":-540,"elapsed":4,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["print(c.device)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"7cu4nPxrsp9V","executionInfo":{"status":"ok","timestamp":1726626545284,"user_tz":-540,"elapsed":1,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["c = c.to('cpu')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9zTgtkjsp9V","outputId":"118d7180-d846-4c79-8222-e415600b805f","executionInfo":{"status":"ok","timestamp":1726626546590,"user_tz":-540,"elapsed":570,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["print(c.device)"]},{"cell_type":"markdown","metadata":{"id":"Xd96DeWesp9V"},"source":["## 3. Autograd"]},{"cell_type":"markdown","metadata":{"id":"ffTzyxGJsp9W"},"source":["Central to all neural networks in PyTorch is the `autograd` package.\n","\n","The `autograd` package provides automatic differentiation for all operations on Tensors.\n","\n","`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n","\n","To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."]},{"cell_type":"markdown","metadata":{"id":"aQFoPjiqsp9W"},"source":["### Example"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXurRLYvsp9W","outputId":"8eb81980-1448-475f-f420-1b675f859063","executionInfo":{"status":"ok","timestamp":1726626547021,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"]}],"source":["x = torch.ones(2, 2, requires_grad=True)\n","print(x)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPVaCg9Csp9W","outputId":"d2762a30-cabc-4db2-c1d3-6e1faba6ed5a","executionInfo":{"status":"ok","timestamp":1726626547498,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)\n"]}],"source":["y = x + 2\n","print(y)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hG5bWmCXsp9W","outputId":"19c920fd-7b8a-48e5-84ee-101857746dac","executionInfo":{"status":"ok","timestamp":1726626548721,"user_tz":-540,"elapsed":4,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[27., 27.],\n","        [27., 27.]], grad_fn=<MulBackward0>)\n"]}],"source":["z = y * y * 3\n","print(z)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KeFRqU-sp9X","outputId":"2be57675-0780-42d2-d784-6f6eeded0a46","executionInfo":{"status":"ok","timestamp":1726626548721,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(27., grad_fn=<MeanBackward0>)\n"]}],"source":["out = z.mean()\n","print(out)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"vkGgBWjtsp9X","executionInfo":{"status":"ok","timestamp":1726626549217,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["y.retain_grad()\n","z.retain_grad()\n","out.backward()"]},{"cell_type":"markdown","metadata":{"id":"5TRbw5HOsp9X"},"source":["![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n","![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzKtqRSIsp9X","outputId":"23e61e40-21d7-4ae0-d38d-f266430077d9","executionInfo":{"status":"ok","timestamp":1726626551180,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2500, 0.2500],\n","        [0.2500, 0.2500]])\n"]}],"source":["print(z.grad)"]},{"cell_type":"markdown","metadata":{"id":"MM28F_Ousp9Y"},"source":["![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n","![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dts8XdHfsp9Y","outputId":"a0f96550-52a8-46d3-ab35-dcea64c231c2","executionInfo":{"status":"ok","timestamp":1726626552523,"user_tz":-540,"elapsed":565,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])\n"]}],"source":["print(y.grad)"]},{"cell_type":"markdown","metadata":{"id":"1kBM2Emesp9Y"},"source":["![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n","![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PN7HmPysp9Y","outputId":"0d978dfb-6911-45fe-e15f-753884e5b914","executionInfo":{"status":"ok","timestamp":1726626553176,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])\n"]}],"source":["print(x.grad)"]},{"cell_type":"markdown","metadata":{"id":"ZTnY5Phpsp9Y"},"source":["### Efficient inference (testing) with torch.no_grad()"]},{"cell_type":"markdown","metadata":{"id":"4Kj0c60Hsp9Y"},"source":["To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n","\n","Situation: when **gradient calculation is not required** e.g., inference\\\n","Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"NqOULboAsp9Y","executionInfo":{"status":"ok","timestamp":1726626554738,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["with torch.no_grad():\n","    x = torch.ones(2, 2, requires_grad=True)\n","    y = x + 2\n","    z = y * y * 3\n","    out = z.mean()"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxw9FVOBsp9Z","outputId":"c1da6033-5c7b-4b41-cb9b-3e7f06850e36","executionInfo":{"status":"ok","timestamp":1726626555158,"user_tz":-540,"elapsed":5,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(27.)"]},"metadata":{},"execution_count":31}],"source":["out"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"aTeg9iG_sp9Z","outputId":"1f2e2d8e-f70e-4d28-d959-0ba37fb0a4a8","executionInfo":{"status":"error","timestamp":1726626555158,"user_tz":-540,"elapsed":5,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-bf3332dd1f01>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## ERROR!!!!: we used torch.no_grad()!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}],"source":["out.backward() ## ERROR!!!!: we used torch.no_grad()!!"]},{"cell_type":"markdown","metadata":{"id":"nje-BGjesp9Z"},"source":["## 4. nn.Module"]},{"cell_type":"markdown","metadata":{"id":"CiVnymh6sp9Z"},"source":["![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"]},{"cell_type":"markdown","metadata":{"id":"gXR5jfpqsp9Z"},"source":["### Using pre-defined modules (subset of models) in PyTorch"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypn-7P5usp9a","outputId":"079068f7-35f5-4dfa-b9c9-63fa971dad0c","executionInfo":{"status":"ok","timestamp":1726626568937,"user_tz":-540,"elapsed":435,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","torch.Size([2, 3])\n"]}],"source":["import torch.nn as nn\n","\n","X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n","\n","print (X)\n","print (X.shape)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"_ad-ZLk5sp9a","executionInfo":{"status":"ok","timestamp":1726626569449,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# input dim 3, output dim 1\n","linear_fn = nn.Linear(3, 1)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIAeq3f-sp9a","outputId":"be17bf3b-9045-42a5-ffc4-1b33fa64459f","executionInfo":{"status":"ok","timestamp":1726626570238,"user_tz":-540,"elapsed":5,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=3, out_features=1, bias=True)"]},"metadata":{},"execution_count":35}],"source":["linear_fn  # WX + b"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smbL2japsp9a","outputId":"6278521a-3bbc-4db7-c82f-7cb44f02bfbe","executionInfo":{"status":"ok","timestamp":1726626570238,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.4851],\n","        [-0.5929]], grad_fn=<AddmmBackward0>)\n","torch.Size([2, 1])\n"]}],"source":["Y = linear_fn(X)\n","print(Y)\n","print(Y.shape)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSlHALX1sp9b","outputId":"71656638-8c25-4bd5-c78c-09b5ee57e208","executionInfo":{"status":"ok","timestamp":1726626570821,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(-1.0780, grad_fn=<SumBackward0>)\n"]}],"source":["Y = Y.sum()\n","print(Y)"]},{"cell_type":"markdown","metadata":{"id":"jvztL-YIsp9b"},"source":["You can use other types of `nn.Module` in PyTorch"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"6AJekGzfsp9b","executionInfo":{"status":"ok","timestamp":1726626571252,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["nn.Conv2d\n","nn.RNNCell\n","nn.LSTMCell\n","nn.GRUCell\n","nn.Transformer;"]},{"cell_type":"markdown","metadata":{"id":"Zlf9096Hsp9b"},"source":["### How can we design a customized model (neural network)?"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"UJgtdOYrsp9c","executionInfo":{"status":"ok","timestamp":1726626572343,"user_tz":-540,"elapsed":1,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, input_dim, output_dim, hidden_dim):\n","        super(Model, self).__init__()\n","        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n","        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n","        self.relu = nn.ReLU()\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.relu(x) # Activation function\n","        x = self.linear_2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"Tr-1kleXsp9c"},"source":["**What is activation function?**\n","- They make non-linearity for deep neural networks\n","- Therefore, deep neural networks can approximate complex functions"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"W_wSvJWmsp9c","executionInfo":{"status":"ok","timestamp":1726626572773,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["nn.Sigmoid\n","nn.ReLU\n","nn.LeakyReLU\n","nn.Tanh;"]},{"cell_type":"markdown","metadata":{"id":"smL1Be1Zsp9d"},"source":["## 5. MNIST classification with PyTorch (Logistic regression & MLP)"]},{"cell_type":"markdown","metadata":{"id":"LvSHOjDTsp9e"},"source":["### What is MNIST & How to do multi-class classification?"]},{"cell_type":"markdown","metadata":{"id":"iy9gJi_hsp9e"},"source":["The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n","\n","Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n","\n","Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."]},{"cell_type":"markdown","metadata":{"id":"mq29uTPusp9e"},"source":["![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"]},{"cell_type":"markdown","metadata":{"id":"Dr5dJKxOsp9e"},"source":["### Load packages"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"AEssd29Vsp9e","executionInfo":{"status":"ok","timestamp":1726626577215,"user_tz":-540,"elapsed":1908,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"6tcrRyzSsp9f"},"source":["### Load datasets for training & testing"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZmTjH_3sp9f","outputId":"fd4180e7-e1d8-44ec-ad7d-ab148fc75ca0","executionInfo":{"status":"ok","timestamp":1726626583216,"user_tz":-540,"elapsed":6004,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 11580413.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 349262.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 3177676.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 5321376.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# MNIST dataset\n","train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n","test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n","\n","# Data loader\n","# mini batch size\n","train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"VCGo8Y1Tsp9f"},"source":["### Define model (we will use one layer classifier first)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"GIxpsDbZsp9g","executionInfo":{"status":"ok","timestamp":1726626583217,"user_tz":-540,"elapsed":19,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# Define model class\n","# This model has one hidden layer\n","class Multinomial_logistic_regression(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(Multinomial_logistic_regression, self).__init__()\n","        self.fc = nn.Linear(input_size, output_size)\n","\n","    def forward(self, x):\n","        out = self.fc(x)\n","        return out"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"aAJBK_1ksp9g","executionInfo":{"status":"ok","timestamp":1726626583217,"user_tz":-540,"elapsed":19,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# Generate model\n","model = Multinomial_logistic_regression(784, 10)  # init(784, 10)\n","# input dim: 784  / output dim: 10"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3eCAztzrsp9g","outputId":"d123566e-f1de-437d-b69d-e82876c7e9c9","executionInfo":{"status":"ok","timestamp":1726626583651,"user_tz":-540,"elapsed":452,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Multinomial_logistic_regression(\n","  (fc): Linear(in_features=784, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":45}],"source":["model"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"gfQW99qHsp9h","executionInfo":{"status":"ok","timestamp":1726626585174,"user_tz":-540,"elapsed":2,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# Upload model to GPU\n","model = model.to('cuda')"]},{"cell_type":"markdown","metadata":{"id":"HDf5serrsp9h"},"source":["### Define optimizer"]},{"cell_type":"markdown","metadata":{"id":"a4vBdxgxsp9h"},"source":["Optimization is about finding the best solution (model parameter) that fits the given dataset!\n","\n","PyTorch optimizer is about **which optimization methods to use for training**\n","\n","We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"EOKbqVsOsp9h","executionInfo":{"status":"ok","timestamp":1726626587244,"user_tz":-540,"elapsed":426,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# Optimizer define\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n","# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"]},{"cell_type":"markdown","metadata":{"id":"wo1HbOMusp9h"},"source":["![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"]},{"cell_type":"markdown","metadata":{"id":"8-DG5f50sp9i"},"source":["### Train the model"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjwUv6E_sp9i","outputId":"882346fa-80c6-43a0-d50a-66e91b66cafc","executionInfo":{"status":"ok","timestamp":1726626663795,"user_tz":-540,"elapsed":74420,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Step [100/469], Loss: 0.2866\n","Epoch [1/10], Step [200/469], Loss: 0.3732\n","Epoch [1/10], Step [300/469], Loss: 0.3412\n","Epoch [1/10], Step [400/469], Loss: 0.2603\n","Epoch [2/10], Step [100/469], Loss: 0.3221\n","Epoch [2/10], Step [200/469], Loss: 0.3929\n","Epoch [2/10], Step [300/469], Loss: 0.3136\n","Epoch [2/10], Step [400/469], Loss: 0.1889\n","Epoch [3/10], Step [100/469], Loss: 0.3739\n","Epoch [3/10], Step [200/469], Loss: 0.2891\n","Epoch [3/10], Step [300/469], Loss: 0.2044\n","Epoch [3/10], Step [400/469], Loss: 0.3156\n","Epoch [4/10], Step [100/469], Loss: 0.2117\n","Epoch [4/10], Step [200/469], Loss: 0.2043\n","Epoch [4/10], Step [300/469], Loss: 0.3319\n","Epoch [4/10], Step [400/469], Loss: 0.2440\n","Epoch [5/10], Step [100/469], Loss: 0.2167\n","Epoch [5/10], Step [200/469], Loss: 0.3058\n","Epoch [5/10], Step [300/469], Loss: 0.2682\n","Epoch [5/10], Step [400/469], Loss: 0.3057\n","Epoch [6/10], Step [100/469], Loss: 0.2286\n","Epoch [6/10], Step [200/469], Loss: 0.3157\n","Epoch [6/10], Step [300/469], Loss: 0.3879\n","Epoch [6/10], Step [400/469], Loss: 0.1724\n","Epoch [7/10], Step [100/469], Loss: 0.2467\n","Epoch [7/10], Step [200/469], Loss: 0.1970\n","Epoch [7/10], Step [300/469], Loss: 0.2406\n","Epoch [7/10], Step [400/469], Loss: 0.1791\n","Epoch [8/10], Step [100/469], Loss: 0.2024\n","Epoch [8/10], Step [200/469], Loss: 0.3257\n","Epoch [8/10], Step [300/469], Loss: 0.2962\n","Epoch [8/10], Step [400/469], Loss: 0.2184\n","Epoch [9/10], Step [100/469], Loss: 0.2787\n","Epoch [9/10], Step [200/469], Loss: 0.3971\n","Epoch [9/10], Step [300/469], Loss: 0.1809\n","Epoch [9/10], Step [400/469], Loss: 0.2424\n","Epoch [10/10], Step [100/469], Loss: 0.3893\n","Epoch [10/10], Step [200/469], Loss: 0.3149\n","Epoch [10/10], Step [300/469], Loss: 0.1884\n","Epoch [10/10], Step [400/469], Loss: 0.1857\n"]}],"source":["# Loss function define (we use cross-entropy)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","#Train the model\n","total_step = len(train_loader)\n","\n","for epoch in range(10):\n","    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n","        # upload to gpu\n","        images = images.reshape(-1, 28*28).to('cuda')\n","        labels = labels.to('cuda')\n","\n","        # Forward\n","        outputs = model(images)  # forwardI(images): get prediction\n","        loss = loss_fn(outputs, labels)  # calculate the loss (cross entropy loss) with ground truth & prediction value\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()  # automatic gradient calculation (autograd)\n","        optimizer.step()  # update model parameter with requires_grad=True\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, 10, i+1, total_step, loss.item()))"]},{"cell_type":"markdown","metadata":{"id":"sRWIix5Ysp9i"},"source":["### Test the model"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5MLTXr6sp9j","outputId":"68368ce2-836c-4d3d-c727-9106ceac7e13","executionInfo":{"status":"ok","timestamp":1726626664964,"user_tz":-540,"elapsed":1186,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 92.11 %\n"]}],"source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, 28*28).to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)  # classification -> get the label prediction of top 1\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"]},{"cell_type":"markdown","metadata":{"id":"6u3eWP6Ysp9j"},"source":["### New model: MLP (multi-layer-perceptron)"]},{"cell_type":"markdown","metadata":{"id":"iubO05oLsp9j"},"source":["Previous model used multinomial logistic regression (one linear layer)\\\n","What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"P8HMCVbtsp9j","executionInfo":{"status":"ok","timestamp":1726626664964,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[],"source":["# New model with multi layer\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(NeuralNet, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, output_size)\n","        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.sigmoid(out)\n","        out = self.fc2(out)\n","        out = self.sigmoid(out)\n","        out = self.fc3(out)\n","        return out"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnhBSqrgsp9k","outputId":"ca2ee2ae-02ec-4107-8d52-f0492775bee8","executionInfo":{"status":"ok","timestamp":1726626735107,"user_tz":-540,"elapsed":70146,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Step [100/469], Loss: 2.2688\n","Epoch [1/10], Step [200/469], Loss: 1.8457\n","Epoch [1/10], Step [300/469], Loss: 1.2593\n","Epoch [1/10], Step [400/469], Loss: 0.8952\n","Epoch [2/10], Step [100/469], Loss: 0.5062\n","Epoch [2/10], Step [200/469], Loss: 0.4822\n","Epoch [2/10], Step [300/469], Loss: 0.5521\n","Epoch [2/10], Step [400/469], Loss: 0.5193\n","Epoch [3/10], Step [100/469], Loss: 0.3083\n","Epoch [3/10], Step [200/469], Loss: 0.2480\n","Epoch [3/10], Step [300/469], Loss: 0.2190\n","Epoch [3/10], Step [400/469], Loss: 0.2254\n","Epoch [4/10], Step [100/469], Loss: 0.3137\n","Epoch [4/10], Step [200/469], Loss: 0.2864\n","Epoch [4/10], Step [300/469], Loss: 0.2320\n","Epoch [4/10], Step [400/469], Loss: 0.3433\n","Epoch [5/10], Step [100/469], Loss: 0.1499\n","Epoch [5/10], Step [200/469], Loss: 0.1563\n","Epoch [5/10], Step [300/469], Loss: 0.2197\n","Epoch [5/10], Step [400/469], Loss: 0.2897\n","Epoch [6/10], Step [100/469], Loss: 0.2610\n","Epoch [6/10], Step [200/469], Loss: 0.1879\n","Epoch [6/10], Step [300/469], Loss: 0.2536\n","Epoch [6/10], Step [400/469], Loss: 0.1353\n","Epoch [7/10], Step [100/469], Loss: 0.1305\n","Epoch [7/10], Step [200/469], Loss: 0.2332\n","Epoch [7/10], Step [300/469], Loss: 0.2310\n","Epoch [7/10], Step [400/469], Loss: 0.3441\n","Epoch [8/10], Step [100/469], Loss: 0.1468\n","Epoch [8/10], Step [200/469], Loss: 0.1990\n","Epoch [8/10], Step [300/469], Loss: 0.0886\n","Epoch [8/10], Step [400/469], Loss: 0.2732\n","Epoch [9/10], Step [100/469], Loss: 0.1266\n","Epoch [9/10], Step [200/469], Loss: 0.1390\n","Epoch [9/10], Step [300/469], Loss: 0.1479\n","Epoch [9/10], Step [400/469], Loss: 0.2140\n","Epoch [10/10], Step [100/469], Loss: 0.1276\n","Epoch [10/10], Step [200/469], Loss: 0.1539\n","Epoch [10/10], Step [300/469], Loss: 0.1549\n","Epoch [10/10], Step [400/469], Loss: 0.2114\n"]}],"source":["# Generate model\n","model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n","# input dim: 784  / hidden dim: 20  / output dim: 10\n","\n","# Upload model to GPU\n","model = model.to('cuda')\n","\n","# Loss function define (we use cross-entropy)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Define optimizer\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n","# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n","\n","# Train the model\n","total_step = len(train_loader)\n","\n","for epoch in range(10):\n","    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n","        # upload to gpu\n","        images = images.reshape(-1, 28*28).to('cuda')\n","        labels = labels.to('cuda')\n","\n","        # Forward\n","        outputs = model(images)  # forwardI(images): get prediction\n","        loss = loss_fn(outputs, labels)  # calculate the loss (cross entropy loss) with ground truth & prediction value\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()  # automatic gradient calculation (autograd)\n","        optimizer.step()  # update model parameter with requires_grad=True\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, 10, i+1, total_step, loss.item()))"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqzS5I06sp9k","outputId":"89672504-5a95-43c6-8e9d-ce9563119c76","executionInfo":{"status":"ok","timestamp":1726626736244,"user_tz":-540,"elapsed":1154,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 94.67 %\n"]}],"source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, 28*28).to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)  # classification -> get the label prediction of top 1\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"]},{"cell_type":"markdown","metadata":{"id":"_jAvwUq1sp9l"},"source":["### Change the following options to obtain better accuracy!! (try it by your-self)"]},{"cell_type":"markdown","metadata":{"id":"jWjgPRMzsp9l"},"source":["#### (1) Model configurations:\n","- size of hidden layer units\n","- number of layers\n","- type of activation function (e.g., relu, tanh, softplus etc.)\n","\n","#### (2) Optimization configurations\n","- learning rate\n","- epoch\n","- type of optimizer\n","- momentem hyperparameter"]},{"cell_type":"code","source":[],"metadata":{"id":"rd1i2urS9wDG","executionInfo":{"status":"ok","timestamp":1726626736244,"user_tz":-540,"elapsed":3,"user":{"displayName":"조수민","userId":"01867040450354592072"}}},"execution_count":52,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"}},"nbformat":4,"nbformat_minor":0}