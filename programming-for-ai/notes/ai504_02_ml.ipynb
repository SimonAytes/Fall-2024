{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bwuJKpNyuuev"},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import sklearn"]},{"cell_type":"markdown","metadata":{"id":"KvUnKHaYuuew"},"source":["### Matplotlib Example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmVSuBTEuuew"},"outputs":[],"source":["# plt.plot(listing of x coordinates, listing of y coordinates)\n","# plot -> continuous line, scatter -> points\n","plt.plot([1,2,3], [3,2,1])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EqkPJ_UkKTk"},"outputs":[],"source":["plt.scatter([1,2,3], [3,2,1])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmpXvNuAkLsN"},"outputs":[],"source":["# together\n","plt.plot([1,2,3], [3,2,1])\n","plt.scatter([1,2,3], [3,2,1])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"E4lqejt_uuex"},"source":["### Drawing a function\n","\n","$-\\left(\\frac{2}{7}x^3 - \\frac{9}{2}x^2 + 15x - 10\\right)$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4P8frEzuuey"},"outputs":[],"source":["foo = lambda x: -(2/7*x**3-9/2*x**2+15*x-10.)\n","x_line = np.linspace(0, 10, 100)\n","\n","# Quiz: Draw the function foo using x_line\n","\n","y_line = foo(x_line)\n","plt.plot(x_line, y_line)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"FFf-Bud6kkK8"},"outputs":[],"source":["# Making 5 continuous points of foo in the domain [0, 10]\n","# with Gaussian noise where mu=0, sigma=0.1 and visualize.\n","\n","sample_size = 10\n","x_sample = np.linspace(0, 10, sample_size)\n","np.random.seed(200)\n","y_sample = foo(x_sample) + np.random.normal(loc=0, scale=1, size=sample_size)\n","\n","plt.scatter(x_sample, y_sample)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIElG0SpmMWF"},"outputs":[],"source":["# put together?\n","\n","plt.plot(x_line, y_line)\n","plt.scatter(x_sample, y_sample)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"PpWaQW1suuey"},"source":["## Linear Regression\n","\n","In the previous section, we first defined the target function,`foo`, and added Gaussian noise to the sampled data points. However, in real-world scenarios, the task is to infer the underlying data distribution function from noisy data points (training data) and predict the \\( y \\)-values for new data points. This time, we will work on the task of restoring the original function, `foo`, from the noisy samples generated earlier.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEaI9yJes7W2"},"outputs":[],"source":["print(x_sample.shape)\n","print(y_sample.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3pNbTOooJBL"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","# Why is there an error?\n","lr = LinearRegression()\n","lr.fit(x_sample, y_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9MJsqSCtpPJ"},"outputs":[],"source":["# from sklearn.linear_model import LinearRegression\n","\n","# lr = LinearRegression()\n","# lr.fit(x_sample.reshape(-1,1), y_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsXBzARmtv78"},"outputs":[],"source":["# Now let's predict\n","\n","y_hat = lr.predict(x_sample)\n","# y_hat = lr.predict(x_sample.reshape(-1,1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xt3ZHWTt8uJ"},"outputs":[],"source":["print(f\"X: {x_sample}\")\n","print(f\"y: {y_sample}\")\n","print(f\"y_hat: {y_hat}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZNwSbC7puDCR"},"outputs":[],"source":["# Calculating Mean Square Error\n","mse = ((y_hat-y_sample)**2).sum() / x_sample.size\n","print(mse)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSp99QTXuuey"},"outputs":[],"source":["plt.plot(x_sample, y_hat)\n","plt.scatter(x_sample, y_sample, color='orange')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymoYbf8cvQzM"},"outputs":[],"source":["# # Adding Legend\n","# plt.plot(x_sample, y_hat, label='Predicted Function')  # Add label for the line\n","# plt.scatter(x_sample, y_sample, color='orange', label='Actual Data')  # Add label for the scatter points\n","# plt.legend()  # Display the legend\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fHkDo_3suuez"},"source":["### Iris Dataset\n","\n","The Iris dataset is a well-known dataset in machine learning and statistics. It contains 150 samples from three species of Iris flowers: Iris setosa, Iris versicolor, and Iris virginica. Each sample includes four features: sepal length, sepal width, petal length, and petal width, all measured in centimeters. These features are used to classify the species of the iris flowers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzCY30KE-ko4"},"outputs":[],"source":["from sklearn.datasets import load_iris\n","X, y = load_iris(return_X_y=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbpIjJ_y-qL8"},"outputs":[],"source":["print(X.shape)\n","print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"Qct6zbh1uuez"},"source":["### Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGbylAyXuuez"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"wgJPdvTXuue0"},"source":["### Classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-GN1cTuuue0"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","logistic = LogisticRegression(random_state=1234)\n","logistic.fit(X_train[:,:2], y_train)\n","\n","from sklearn.svm import SVC\n","svc = SVC(C=1.0, kernel='poly', degree=3)\n","svc.fit(X_train[:,:2], y_train)\n","\n","from sklearn.tree import DecisionTreeClassifier as DTC\n","tree = DTC(max_depth=2, random_state=1234)\n","tree.fit(X_train[:, :2], y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ek7xs0vIuue0"},"outputs":[],"source":["# Use the model's predict() to calculate the test accuracy.\n","\n","y_svc = svc.predict(X_test[:, :2])\n","print(y_svc)\n","print((y_test == y_svc).mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qL97Wt8KyoQx"},"outputs":[],"source":["# More simple way\n","\n","print(svc.score(X_test[:, :2], y_test))\n","# print(tree.score(X_test[:, :2], y_test))\n","# print(logistic.score(X_test[:, :2], y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2BcER-lDchM"},"outputs":[],"source":["y_logistic = logistic.predict(X_test[:, :2])\n","y_svc = svc.predict(X_test[:, :2])\n","y_tree = tree.predict(X_test[:, :2])\n","\n","plt.figure(figsize=(20,5))\n","\n","plt.subplot(141)\n","plt.title('Logistic Regression')\n","plt.scatter(X_test[:, 0], X_test[:, 1], c=y_logistic)\n","\n","plt.subplot(142)\n","plt.title('SVM')\n","plt.scatter(X_test[:, 0], X_test[:, 1], c=y_svc)\n","\n","plt.subplot(143)\n","plt.title('Decision Tree')\n","plt.scatter(X_test[:, 0], X_test[:, 1], c=y_tree)\n","\n","plt.subplot(144)\n","plt.title('Ground Truth')\n","plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Aa-voAPoz09U"},"source":["# Adding Decision boundary Using AI504 Chatbot?"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
